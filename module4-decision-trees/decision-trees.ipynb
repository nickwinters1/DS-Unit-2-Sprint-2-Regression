{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Lambda School Data Science — Tree Ensembles_ \n",
    "\n",
    "# Decision Trees\n",
    "\n",
    "### Links\n",
    "- A Visual Introduction to Machine Learning, [Part 1: A Decision Tree](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/),  and [Part 2: Bias and Variance](http://www.r2d3.us/visual-intro-to-machine-learning-part-2/)\n",
    "- [Decision Trees: Advantages & Disadvantages](https://christophm.github.io/interpretable-ml-book/tree.html#advantages-2)\n",
    "- [How decision trees work](https://brohrer.github.io/how_decision_trees_work.html)\n",
    "- [How a Russian mathematician constructed a decision tree - by hand - to solve a medical problem](http://fastml.com/how-a-russian-mathematician-constructed-a-decision-tree-by-hand-to-solve-a-medical-problem/)\n",
    "- [Let’s Write a Decision Tree Classifier from Scratch](https://www.youtube.com/watch?v=LDRbO9a6XPU) — _Don’t worry about understanding the code, just get introduced to the concepts. This 10 minute video has excellent diagrams and explanations._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries to install\n",
    "\n",
    "#### graphviz (to visualize trees)\n",
    "Anaconda:  \n",
    "```conda install python-graphviz```\n",
    "\n",
    "Google Colab:  \n",
    "```!pip install graphviz\n",
    "!apt-get install graphviz\n",
    "```\n",
    "\n",
    "#### ipywidgets (optional, for interactive widgets)\n",
    "Anaconda: Already installed\n",
    "Google Colab: [Doesn't work](https://github.com/googlecolab/colabtools/issues/60#issuecomment-462529981)\n",
    "\n",
    "#### mlxtend (to plot decision regions)\n",
    "[mlxtend.plotting.plot_decision_regions](http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/): `pip install mlxtend`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import graphviz\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz\n",
    "\n",
    "\n",
    "def viztree(decision_tree, feature_names):\n",
    "    \"\"\"Visualize a decision tree\"\"\"\n",
    "    dot_data = export_graphviz(decision_tree, out_file=None, feature_names=feature_names, \n",
    "                               filled=True, rounded=True)   \n",
    "    return graphviz.Source(dot_data)\n",
    "\n",
    "\n",
    "def viz3D(fitted_model, df, feature1, feature2, target='', num=100):\n",
    "    \"\"\"\n",
    "    Visualize model predictions in 3D, for regression or binary classification\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fitted_model : scikit-learn model, already fitted\n",
    "    df : pandas dataframe, which was used to fit model\n",
    "    feature1 : string, name of feature 1\n",
    "    feature2 : string, name of feature 2\n",
    "    target : string, name of target\n",
    "    num : int, number of grid points for each feature\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    https://jakevdp.github.io/PythonDataScienceHandbook/04.12-three-dimensional-plotting.html\n",
    "    https://scikit-learn.org/stable/auto_examples/tree/plot_iris.html  \n",
    "    \"\"\"\n",
    "    x1 = np.linspace(df[feature1].min(), df[feature1].max(), num)\n",
    "    x2 = np.linspace(df[feature2].min(), df[feature2].max(), num)\n",
    "    X1, X2 = np.meshgrid(x1, x2)\n",
    "    X = np.c_[X1.flatten(), X2.flatten()]\n",
    "    if hasattr(fitted_model, 'predict_proba'):\n",
    "        predicted = fitted_model.predict_proba(X)[:,1]\n",
    "    else:\n",
    "        predicted = fitted_model.predict(X)\n",
    "    Z = predicted.reshape(num, num)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.plot_surface(X1, X2, Z, cmap='viridis')\n",
    "    ax.set_xlabel(feature1)\n",
    "    ax.set_ylabel(feature2)\n",
    "    ax.set_zlabel(target)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Golf Putts (1 feature, non-linear)\n",
    "\n",
    "https://statmodeling.stat.columbia.edu/2008/12/04/the_golf_puttin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "columns = ['distance', 'tries', 'successes']\n",
    "data = [[2, 1443, 1346],\n",
    "        [3, 694, 577],\n",
    "        [4, 455, 337],\n",
    "        [5, 353, 208],\n",
    "        [6, 272, 149],\n",
    "        [7, 256, 136],\n",
    "        [8, 240, 111],\n",
    "        [9, 217, 69],\n",
    "        [10, 200, 67],\n",
    "        [11, 237, 75],\n",
    "        [12, 202, 52],\n",
    "        [13, 192, 46],\n",
    "        [14, 174, 54],\n",
    "        [15, 167, 28],\n",
    "        [16, 201, 27],\n",
    "        [17, 195, 31],\n",
    "        [18, 191, 33],\n",
    "        [19, 147, 20],\n",
    "        [20, 152, 24]]\n",
    "\n",
    "putts = pd.DataFrame(columns=columns, data=data)\n",
    "putts['rate of success'] = putts['successes'] / putts['tries']\n",
    "putts.plot('distance', 'rate of success', kind='scatter', title='Golf Putts');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "putts_X = putts[['distance']]\n",
    "putts_y = putts['rate of success']\n",
    "lr = LinearRegression()\n",
    "lr.fit(putts_X, putts_y)\n",
    "print('R^2 Score', lr.score(putts_X, putts_y))\n",
    "ax = putts.plot('distance', 'rate of success', kind='scatter', title='Golf Putts')\n",
    "ax.plot(putts_X, lr.predict(putts_X));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def viztree(decision_tree, feature_names):\n",
    "    dot_data = export_graphviz(decision_tree, out_file=None, feature_names=feature_names, \n",
    "                               filled=True, rounded=True)   \n",
    "    return graphviz.Source(dot_data)\n",
    "\n",
    "def putts_tree(max_depth=1):\n",
    "    tree = DecisionTreeRegressor(max_depth=max_depth)\n",
    "    tree.fit(putts_X, putts_y)\n",
    "    print('R^2 Score', tree.score(putts_X, putts_y))\n",
    "    ax = putts.plot('distance', 'rate of success', kind='scatter', title='Golf Putts')\n",
    "    ax.step(putts_X, tree.predict(putts_X), where='mid')\n",
    "    plt.show()\n",
    "    display(viztree(tree, feature_names=['distance']))\n",
    "\n",
    "interact(putts_tree, max_depth=(1,6,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predictions = []\n",
    "for distance in putts['distance']:\n",
    "    samples = putts.copy()\n",
    "    if distance <= 8.5:\n",
    "        samples = samples.query('distance <= 8.5')\n",
    "        if distance <= 4.5:\n",
    "            samples = samples.query('distance <= 4.5')\n",
    "        else:\n",
    "            samples = samples.query('distance > 4.5')\n",
    "    else:\n",
    "        samples = samples.query('distance > 8.5')\n",
    "        if distance <= 14.5:\n",
    "            samples = samples.query('distance <= 14.5')\n",
    "        else:\n",
    "            samples = samples.query('distance > 14.5')\n",
    "    prediction = samples['rate of success'].mean()\n",
    "    predictions.append(prediction)\n",
    "    \n",
    "print('R^2 Score', r2_score(putts_y, predictions))\n",
    "ax = putts.plot('distance', 'rate of success', kind='scatter', title='Golf Putts')\n",
    "ax.step(putts_X, predictions, where='mid');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wave (1 feature, non-monotonic, train/test split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Based on http://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html\n",
    "def make_data():\n",
    "    import numpy as np\n",
    "    rng = np.random.RandomState(1)\n",
    "    X = np.sort(5 * rng.rand(80, 1), axis=0)\n",
    "    y = np.sin(X).ravel()\n",
    "    y[::5] += 2 * (0.5 - rng.rand(16))\n",
    "    return X, y\n",
    "\n",
    "wave_X, wave_y = make_data()\n",
    "wave_X_train, wave_X_test, wave_y_train, wave_y_test = train_test_split(\n",
    "    wave_X, wave_y, test_size=0.25, random_state=42)\n",
    "\n",
    "def regress_wave(max_depth=1):\n",
    "    tree = DecisionTreeRegressor(max_depth=max_depth)\n",
    "    tree.fit(wave_X_train, wave_y_train)\n",
    "    print('Train R^2 score:', tree.score(wave_X_train, wave_y_train))\n",
    "    print('Test R^2 score:', tree.score(wave_X_test, wave_y_test))\n",
    "    plt.scatter(wave_X_train, wave_y_train)\n",
    "    plt.scatter(wave_X_test, wave_y_test)\n",
    "    plt.step(wave_X, tree.predict(wave_X), where='mid')\n",
    "    plt.show()\n",
    "    \n",
    "interact(regress_wave, max_depth=(1,8,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple housing (2 features)\n",
    "\n",
    "https://christophm.github.io/interpretable-ml-book/interaction.html#feature-interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Price', 'Good Location', 'Big Size']\n",
    "\n",
    "data = [[300000, 1, 1], \n",
    "        [200000, 1, 0], \n",
    "        [250000, 0, 1], \n",
    "        [150000, 0, 0]]\n",
    "\n",
    "house = pd.DataFrame(columns=columns, data=data)\n",
    "house"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_X = house.drop(columns='Price')\n",
    "house_y = house['Price']\n",
    "lr = LinearRegression()\n",
    "lr.fit(house_X, house_y)\n",
    "print('R^2', lr.score(house_X, house_y))\n",
    "print('Intercept \\t', lr.intercept_)\n",
    "coefficients = pd.Series(lr.coef_, house_X.columns)\n",
    "print(coefficients.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "viz3D(lr, house, feature1='Good Location', feature2='Big Size', target='Price');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(house_X, house_y)\n",
    "print('R^2', tree.score(house_X, house_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "viz3D(tree, house, feature1='Good Location', feature2='Big Size', target='Price');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "table = house.pivot_table('Price', 'Good Location', 'Big Size')\n",
    "sns.heatmap(table, annot=True, fmt='d', cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple housing, with a twist (feature interactions, 2 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house.loc[0, 'Price'] = 400000\n",
    "house_X = house.drop(columns='Price')\n",
    "house_y = house['Price']\n",
    "house"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS Regression, without engineering an interaction term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(house_X, house_y)\n",
    "print('R^2', lr.score(house_X, house_y))\n",
    "print('Intercept \\t', lr.intercept_)\n",
    "coefficients = pd.Series(lr.coef_, house_X.columns)\n",
    "print(coefficients.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree, without engineering an interaction term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(house_X, house_y)\n",
    "print('R^2', tree.score(house_X, house_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS Regression, with engineered interaction term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house['Good Location * Big Size'] = house['Good Location'] * house['Big Size']\n",
    "house_X = house.drop(columns='Price')\n",
    "house_y = house['Price']\n",
    "house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(house_X, house_y)\n",
    "print('R^2', lr.score(house_X, house_y))\n",
    "print('Intercept \\t', lr.intercept_)\n",
    "coefficients = pd.Series(lr.coef_, house_X.columns)\n",
    "print(coefficients.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree, with engineered interaction term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(house_X, house_y)\n",
    "print('R^2', tree.score(house_X, house_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic (classification, interactions, non-linear / non-monotonic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset('titanic')\n",
    "titanic['sex'] = (titanic['sex'] == 'female').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer()\n",
    "titanic_X = imputer.fit_transform(titanic[['age', 'sex']])\n",
    "titanic_y = titanic['survived']\n",
    "tree = DecisionTreeClassifier(max_depth=4)\n",
    "tree.fit(titanic_X, titanic_y)\n",
    "print('Accuracy', tree.score(titanic_X, titanic_y))\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "viz3D(tree, titanic, feature1='age', feature2='sex', target='survived');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression(solver='lbfgs')\n",
    "logistic.fit(titanic_X, titanic_y)\n",
    "print('Accuracy', tree.score(titanic_X, titanic_y))\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "viz3D(logistic, titanic, feature1='age', feature2='sex', target='survived');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
